{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleSeq2Seq(Bhavya).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qjZJVA4u4Ll",
        "outputId": "3f02b0fc-7b02-4df2-8130-1d346318b82b"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yionn9qwu94N"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "from string import digits\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, Input, Dense,Embedding\n",
        "from keras.models import Model,load_model\n",
        "# from keras.utils import plot_model\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import model_from_json\n",
        "import pickle as pkl\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17fitFiIvE28"
      },
      "source": [
        "data_path = \"/content/drive/MyDrive/pol.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6yZx20a6tvI"
      },
      "source": [
        "with open('/content/drive/MyDrive/pol.txt','r',encoding=\"utf8\") as f:\n",
        "  data = f.read()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uESWoxVq6pUF",
        "outputId": "d46dc8ea-1543-411d-917d-018c47047ba5"
      },
      "source": [
        "# we need to clean the data\n",
        "uncleaned_data_list = data.split('\\n')\n",
        "print(len(uncleaned_data_list))\n",
        "\n",
        "uncleaned_data_list = uncleaned_data_list[:40465]\n",
        "print(len(uncleaned_data_list))\n",
        "\n",
        "english_word = []\n",
        "polish_word = []\n",
        "# cleaned_data_list = []\n",
        "for word in uncleaned_data_list:\n",
        "  english_word.append(word.split('\\t')[:-1][0])\n",
        "  polish_word.append(word.split('\\t')[:-1][1])\n",
        "  \n",
        "print(len(english_word), len(polish_word))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40466\n",
            "40465\n",
            "40465 40465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhInH3fu7q5l"
      },
      "source": [
        "language_data = pd.DataFrame(columns=['English','Polish'])\n",
        "language_data['English'] = english_word\n",
        "language_data['Polish'] = polish_word\n",
        "\n",
        "# saving to csv\n",
        "language_data.to_csv('language_data.csv', index=False)\n",
        "\n",
        "# loading data from csv\n",
        "language_data = pd.read_csv('language_data.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjE4aRFbvS-E"
      },
      "source": [
        "lines= pd.read_table('language_data.csv', delimiter=\",\", names=['eng', 'pol'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "5uv0qgjX6Yk7",
        "outputId": "f01d316d-34b9-413a-d0bc-d6f5e3256cfb"
      },
      "source": [
        "lines"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>pol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>English</td>\n",
              "      <td>Polish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Idź.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Cześć.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Uciekaj!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Biegnij.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40461</th>\n",
              "      <td>No matter how much you try to convince people ...</td>\n",
              "      <td>Nieważne, jak bardzo usiłujesz przekonać ludzi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40462</th>\n",
              "      <td>A child who is a native speaker usually knows ...</td>\n",
              "      <td>Dziecko zwykle wie o swoim języku ojczystym rz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40463</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Zwykle jest wiele stron internetowych na każdy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40464</th>\n",
              "      <td>If you want to sound like a native speaker, yo...</td>\n",
              "      <td>Jeśli chcesz mówić jak rodzimy użytkownik, mus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40465</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Jeśli ktoś, kto nas nie zna, mówi, że mówimy j...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40466 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     eng                                                pol\n",
              "0                                                English                                             Polish\n",
              "1                                                    Go.                                               Idź.\n",
              "2                                                    Hi.                                             Cześć.\n",
              "3                                                   Run!                                           Uciekaj!\n",
              "4                                                   Run.                                           Biegnij.\n",
              "...                                                  ...                                                ...\n",
              "40461  No matter how much you try to convince people ...  Nieważne, jak bardzo usiłujesz przekonać ludzi...\n",
              "40462  A child who is a native speaker usually knows ...  Dziecko zwykle wie o swoim języku ojczystym rz...\n",
              "40463  Since there are usually multiple websites on a...  Zwykle jest wiele stron internetowych na każdy...\n",
              "40464  If you want to sound like a native speaker, yo...  Jeśli chcesz mówić jak rodzimy użytkownik, mus...\n",
              "40465  If someone who doesn't know your background sa...  Jeśli ktoś, kto nas nie zna, mówi, że mówimy j...\n",
              "\n",
              "[40466 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9qfSjsEX6na"
      },
      "source": [
        "\n",
        "\n",
        "# Lowercase all characters\n",
        "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
        "lines.pol=lines.pol.apply(lambda x: x.lower())\n",
        "\n",
        "# Remove quotes\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines.pol=lines.pol.apply(lambda x: re.sub(\"'\", '', x))\n",
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "\n",
        "# Remove all the special characters\n",
        "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines.pol=lines.pol.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "\n",
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
        "lines.pol = lines.pol.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# Remove extra spaces\n",
        "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
        "lines.pol=lines.pol.apply(lambda x: x.strip())\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines.pol=lines.pol.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "\n",
        "# Add start and end tokens to target sequences\n",
        "lines.eng = lines.eng.apply(lambda x : 'START_ '+ x + ' _END')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaid4LZI8WbI",
        "outputId": "2da7d296-7570-4702-f349-1cad6a6b14bb"
      },
      "source": [
        "lines.eng"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                      START_ english _END\n",
              "1                                           START_ go _END\n",
              "2                                           START_ hi _END\n",
              "3                                          START_ run _END\n",
              "4                                          START_ run _END\n",
              "                               ...                        \n",
              "40461    START_ no matter how much you try to convince ...\n",
              "40462    START_ a child who is a native speaker usually...\n",
              "40463    START_ since there are usually multiple websit...\n",
              "40464    START_ if you want to sound like a native spea...\n",
              "40465    START_ if someone who doesnt know your backgro...\n",
              "Name: eng, Length: 40466, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jqg5_Bs8YBt"
      },
      "source": [
        "# Vocabulary of English\n",
        "all_eng_words=set()\n",
        "for eng in lines.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "# Vocabulary of French \n",
        "all_polish_words=set()\n",
        "for pol in lines.pol:\n",
        "    for word in pol.split():\n",
        "        if word not in all_polish_words:\n",
        "            all_polish_words.add(word)\n",
        "\n",
        "# Max Length of source sequence\n",
        "lenght_list=[]\n",
        "for l in lines.pol:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "\n",
        "# Max Length of target sequence\n",
        "lenght_list=[]\n",
        "for l in lines.eng:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "\n",
        "input_words = sorted(list(all_polish_words))\n",
        "target_words = sorted(list(all_eng_words))\n",
        "\n",
        "# Calculate Vocab size for both source and target\n",
        "num_encoder_tokens = len(all_polish_words)\n",
        "num_encoder_tokens += 1\n",
        "num_decoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens += 1 # For zero padding\n",
        "\n",
        "# Create word to token dictionary for both source and target\n",
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
        "\n",
        "# Create token to word dictionary for both source and target\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n36CcoYy88as",
        "outputId": "7acde57c-9438-41a5-f3b6-437238c0148f"
      },
      "source": [
        "\n",
        "# Train - Test Split\n",
        "X, y = lines.pol,lines.eng\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.01,random_state=101)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40061,), (405,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDvqKdT-8_3z"
      },
      "source": [
        "\n",
        "X_train.to_pickle('X_train.pkl')\n",
        "X_test.to_pickle('X_test.pkl')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01o-u_I69U47"
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tX889Wg9aPM"
      },
      "source": [
        "latent_dim = 300"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Tt0w439c2y"
      },
      "source": [
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l1mSLr69eRu"
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcT42dQn9haC"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvDHThm89kFx"
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 50"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OrBF0YB9l07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c9b004-560a-4a57-8400-258f1fcd8e87"
      },
      "source": [
        "\n",
        "r = model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "312/312 [==============================] - 84s 199ms/step - loss: 0.8279 - accuracy: 0.1803 - val_loss: 0.6670 - val_accuracy: 0.2620\n",
            "Epoch 2/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.6312 - accuracy: 0.2864 - val_loss: 0.5787 - val_accuracy: 0.3291\n",
            "Epoch 3/50\n",
            "312/312 [==============================] - 59s 189ms/step - loss: 0.5465 - accuracy: 0.3554 - val_loss: 0.5308 - val_accuracy: 0.3759\n",
            "Epoch 4/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.4915 - accuracy: 0.4052 - val_loss: 0.4958 - val_accuracy: 0.4067\n",
            "Epoch 5/50\n",
            "312/312 [==============================] - 59s 189ms/step - loss: 0.4488 - accuracy: 0.4453 - val_loss: 0.4742 - val_accuracy: 0.4282\n",
            "Epoch 6/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.4116 - accuracy: 0.4817 - val_loss: 0.4545 - val_accuracy: 0.4501\n",
            "Epoch 7/50\n",
            "312/312 [==============================] - 58s 184ms/step - loss: 0.3794 - accuracy: 0.5162 - val_loss: 0.4399 - val_accuracy: 0.4668\n",
            "Epoch 8/50\n",
            "312/312 [==============================] - 59s 189ms/step - loss: 0.3508 - accuracy: 0.5482 - val_loss: 0.4272 - val_accuracy: 0.4883\n",
            "Epoch 9/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.3245 - accuracy: 0.5777 - val_loss: 0.4164 - val_accuracy: 0.4965\n",
            "Epoch 10/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.3005 - accuracy: 0.6064 - val_loss: 0.4122 - val_accuracy: 0.5113\n",
            "Epoch 11/50\n",
            "312/312 [==============================] - 58s 185ms/step - loss: 0.2785 - accuracy: 0.6346 - val_loss: 0.4042 - val_accuracy: 0.5291\n",
            "Epoch 12/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.2580 - accuracy: 0.6604 - val_loss: 0.4013 - val_accuracy: 0.5280\n",
            "Epoch 13/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.2388 - accuracy: 0.6852 - val_loss: 0.4004 - val_accuracy: 0.5391\n",
            "Epoch 14/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.2210 - accuracy: 0.7089 - val_loss: 0.3973 - val_accuracy: 0.5410\n",
            "Epoch 15/50\n",
            "312/312 [==============================] - 59s 188ms/step - loss: 0.2051 - accuracy: 0.7308 - val_loss: 0.3984 - val_accuracy: 0.5447\n",
            "Epoch 16/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.1910 - accuracy: 0.7513 - val_loss: 0.4000 - val_accuracy: 0.5451\n",
            "Epoch 17/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.1784 - accuracy: 0.7689 - val_loss: 0.4012 - val_accuracy: 0.5443\n",
            "Epoch 18/50\n",
            "312/312 [==============================] - 58s 185ms/step - loss: 0.1665 - accuracy: 0.7860 - val_loss: 0.4001 - val_accuracy: 0.5429\n",
            "Epoch 19/50\n",
            "312/312 [==============================] - 59s 189ms/step - loss: 0.1544 - accuracy: 0.8041 - val_loss: 0.4033 - val_accuracy: 0.5429\n",
            "Epoch 20/50\n",
            "312/312 [==============================] - 57s 184ms/step - loss: 0.1432 - accuracy: 0.8198 - val_loss: 0.4033 - val_accuracy: 0.5443\n",
            "Epoch 21/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.1334 - accuracy: 0.8344 - val_loss: 0.4053 - val_accuracy: 0.5488\n",
            "Epoch 22/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.1242 - accuracy: 0.8477 - val_loss: 0.4068 - val_accuracy: 0.5455\n",
            "Epoch 23/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.1159 - accuracy: 0.8594 - val_loss: 0.4120 - val_accuracy: 0.5488\n",
            "Epoch 24/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.1081 - accuracy: 0.8713 - val_loss: 0.4106 - val_accuracy: 0.5488\n",
            "Epoch 25/50\n",
            "312/312 [==============================] - 58s 185ms/step - loss: 0.1008 - accuracy: 0.8817 - val_loss: 0.4157 - val_accuracy: 0.5462\n",
            "Epoch 26/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0944 - accuracy: 0.8901 - val_loss: 0.4195 - val_accuracy: 0.5421\n",
            "Epoch 27/50\n",
            "312/312 [==============================] - 59s 188ms/step - loss: 0.0884 - accuracy: 0.8994 - val_loss: 0.4228 - val_accuracy: 0.5477\n",
            "Epoch 28/50\n",
            "312/312 [==============================] - 59s 189ms/step - loss: 0.0824 - accuracy: 0.9081 - val_loss: 0.4257 - val_accuracy: 0.5440\n",
            "Epoch 29/50\n",
            "312/312 [==============================] - 59s 187ms/step - loss: 0.0769 - accuracy: 0.9148 - val_loss: 0.4253 - val_accuracy: 0.5429\n",
            "Epoch 30/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0721 - accuracy: 0.9217 - val_loss: 0.4299 - val_accuracy: 0.5451\n",
            "Epoch 31/50\n",
            "312/312 [==============================] - 59s 188ms/step - loss: 0.0679 - accuracy: 0.9274 - val_loss: 0.4276 - val_accuracy: 0.5451\n",
            "Epoch 32/50\n",
            "312/312 [==============================] - 58s 185ms/step - loss: 0.0640 - accuracy: 0.9320 - val_loss: 0.4346 - val_accuracy: 0.5458\n",
            "Epoch 33/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0603 - accuracy: 0.9367 - val_loss: 0.4326 - val_accuracy: 0.5481\n",
            "Epoch 34/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0569 - accuracy: 0.9409 - val_loss: 0.4376 - val_accuracy: 0.5410\n",
            "Epoch 35/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0538 - accuracy: 0.9445 - val_loss: 0.4438 - val_accuracy: 0.5414\n",
            "Epoch 36/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.0513 - accuracy: 0.9472 - val_loss: 0.4431 - val_accuracy: 0.5414\n",
            "Epoch 37/50\n",
            "312/312 [==============================] - 58s 185ms/step - loss: 0.0485 - accuracy: 0.9507 - val_loss: 0.4471 - val_accuracy: 0.5462\n",
            "Epoch 38/50\n",
            "312/312 [==============================] - 57s 184ms/step - loss: 0.0459 - accuracy: 0.9534 - val_loss: 0.4496 - val_accuracy: 0.5436\n",
            "Epoch 39/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0436 - accuracy: 0.9563 - val_loss: 0.4501 - val_accuracy: 0.5447\n",
            "Epoch 40/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.0416 - accuracy: 0.9579 - val_loss: 0.4509 - val_accuracy: 0.5429\n",
            "Epoch 41/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.0395 - accuracy: 0.9607 - val_loss: 0.4565 - val_accuracy: 0.5391\n",
            "Epoch 42/50\n",
            "312/312 [==============================] - 57s 184ms/step - loss: 0.0376 - accuracy: 0.9623 - val_loss: 0.4602 - val_accuracy: 0.5373\n",
            "Epoch 43/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.0361 - accuracy: 0.9637 - val_loss: 0.4595 - val_accuracy: 0.5462\n",
            "Epoch 44/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.0346 - accuracy: 0.9652 - val_loss: 0.4580 - val_accuracy: 0.5388\n",
            "Epoch 45/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.0330 - accuracy: 0.9667 - val_loss: 0.4659 - val_accuracy: 0.5377\n",
            "Epoch 46/50\n",
            "312/312 [==============================] - 59s 188ms/step - loss: 0.0316 - accuracy: 0.9680 - val_loss: 0.4683 - val_accuracy: 0.5347\n",
            "Epoch 47/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0308 - accuracy: 0.9685 - val_loss: 0.4685 - val_accuracy: 0.5347\n",
            "Epoch 48/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0295 - accuracy: 0.9697 - val_loss: 0.4711 - val_accuracy: 0.5365\n",
            "Epoch 49/50\n",
            "312/312 [==============================] - 58s 186ms/step - loss: 0.0283 - accuracy: 0.9710 - val_loss: 0.4714 - val_accuracy: 0.5369\n",
            "Epoch 50/50\n",
            "312/312 [==============================] - 58s 187ms/step - loss: 0.0272 - accuracy: 0.9716 - val_loss: 0.4766 - val_accuracy: 0.5365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEcwOLTQAHKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d564d561-1c43-4aac-bee3-18bbda27176c"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/Pol-Eng Master/s2sPE.h5\")\n",
        "model.save(\"/content/drive/MyDrive/Pol-Eng Master/s2sPE\",save_format='tf')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Pol-Eng Master/s2sPE/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Pol-Eng Master/s2sPE/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qhT5Gr8tRtu"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CYIEkNttITz"
      },
      "source": [
        "model = load_model(\"/content/drive/MyDrive/Pol-Eng Master/s2sPE.h5\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Zr3EE9Jt0w"
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lSoY8_N9nE1"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwcIIsUHw7Zi"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "bleu_score = []\n",
        "sent_len = []"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eINmTgJpJlTN",
        "outputId": "63ce9173-e469-4fc1-9b24-07d028419dd9"
      },
      "source": [
        "test_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "k=-1\n",
        "(test_gen)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object generate_batch at 0x7f692f4c4bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj2xwbGCJnEu",
        "outputId": "b3b509e5-8630-4332-f2a6-e8a42b4c9d00"
      },
      "source": [
        "for k in range(0,10):\n",
        "  print(k)\n",
        "  (input_seq, actual_output), _ = next(test_gen)\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('Input Polish sentence:', X_test[k:k+1].values[0])\n",
        "  print('Actual English Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "  reference = [y_test[k:k+1].values[0][6:-4].split()]\n",
        "  length = len(y_test[k:k+1].values[0][6:-4].split())\n",
        "  sent_len.append(sent_len)\n",
        "  print(reference)\n",
        "  print('Predicted English Translation:', decoded_sentence[:-4])\n",
        "  candidate = decoded_sentence[:-4].split()\n",
        "  score = sentence_bleu(reference, candidate)\n",
        "  bleu_score.append(score)\n",
        "\n",
        "  print('BLEU score -> {}'.format(score))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Input Polish sentence: to nasz ojciec\n",
            "Actual English Translation:  that is our father \n",
            "[['that', 'is', 'our', 'father']]\n",
            "Predicted English Translation:  thats our father \n",
            "BLEU score -> 0.5444460596606694\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input Polish sentence: ona robi wrażenie\n",
            "Actual English Translation:  shes awesome \n",
            "[['shes', 'awesome']]\n",
            "Predicted English Translation:  she is her a friend \n",
            "BLEU score -> 0\n",
            "2\n",
            "Input Polish sentence: chcę dla ciebie tego co najlepsze\n",
            "Actual English Translation:  i want whats best for you \n",
            "[['i', 'want', 'whats', 'best', 'for', 'you']]\n",
            "Predicted English Translation:  i want to do it for you say that \n",
            "BLEU score -> 0.5773502691896258\n",
            "3\n",
            "Input Polish sentence: oni cię nie chcą\n",
            "Actual English Translation:  they dont want you \n",
            "[['they', 'dont', 'want', 'you']]\n",
            "Predicted English Translation:  they dont want to do \n",
            "BLEU score -> 0.5623413251903491\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input Polish sentence: gdyby tutaj teraz była mógłbym jej powiedzieć prawdę\n",
            "Actual English Translation:  if she were here now i could tell her the truth \n",
            "[['if', 'she', 'were', 'here', 'now', 'i', 'could', 'tell', 'her', 'the', 'truth']]\n",
            "Predicted English Translation:  if you were had the same i told you how to never \n",
            "BLEU score -> 0.7598356856515925\n",
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input Polish sentence: on był bardzo stary i schorowany\n",
            "Actual English Translation:  he was very old and ill \n",
            "[['he', 'was', 'very', 'old', 'and', 'ill']]\n",
            "Predicted English Translation:  he was married and old man was blue \n",
            "BLEU score -> 0.5169731539571706\n",
            "6\n",
            "Input Polish sentence: tylko ty możesz to zrobić\n",
            "Actual English Translation:  youre the only one who can do this \n",
            "[['youre', 'the', 'only', 'one', 'who', 'can', 'do', 'this']]\n",
            "Predicted English Translation:  you are just do that you \n",
            "BLEU score -> 0.45782273986766686\n",
            "7\n",
            "Input Polish sentence: wszyscy zachwycali się jej odwagą\n",
            "Actual English Translation:  everyone marvelled at her courage \n",
            "[['everyone', 'marvelled', 'at', 'her', 'courage']]\n",
            "Predicted English Translation:  everyone everyone want to cook \n",
            "BLEU score -> 0.668740304976422\n",
            "8\n",
            "Input Polish sentence: lubię słuchać podkastów\n",
            "Actual English Translation:  i like to listen to podcasts \n",
            "[['i', 'like', 'to', 'listen', 'to', 'podcasts']]\n",
            "Predicted English Translation:  i like to catch up like \n",
            "BLEU score -> 0.4728708045015879\n",
            "9\n",
            "Input Polish sentence: nie wszyscy tutaj mówią po francusku\n",
            "Actual English Translation:  not everyone here can speak french \n",
            "[['not', 'everyone', 'here', 'can', 'speak', 'french']]\n",
            "Predicted English Translation:  not all one of the man speak french \n",
            "BLEU score -> 0.48109772909788073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEGVhVZWLDmq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}